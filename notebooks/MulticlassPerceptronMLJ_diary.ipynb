{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using MetadataTools,  DocStringExtensions\n",
    "using Random: shuffle, MersenneTwister\n",
    "\n",
    "# export MulticlassPerceptronClassifier, fit!, predict\n",
    "using LinearAlgebra: mul!\n",
    "using SparseArrays\n",
    "\n",
    "import MLJBase\n",
    "using MLJ\n",
    "#using Revise\n",
    "\n",
    "#> needed for classifiers:\n",
    "using CategoricalArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the model struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A model is an object storing hyperparameters associated with some machine learning algorithm. In MLJ, hyperparameters include configuration parameters, like the number of threads, and special instructions, such as \"compute feature rankings\", which may or may not affect the final learning outcome. However, the logging level (verbosity below) is excluded.\n",
    "**\n",
    "\n",
    "\n",
    "In MLJ I would do\n",
    "\n",
    "```\n",
    "mutable struct MulticlassPerceptronClassifier <: MLJBase.Deterministic\n",
    "    n_epochs::Int\n",
    "    n_epoch_patience::Int\n",
    "    f_average_weights::Bool\n",
    "    f_shuffle_data::Bool\n",
    "    element_type::DataType\n",
    "end\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mutable struct MulticlassPerceptronClassifier <: MLJBase.Deterministic\n",
    "    n_epochs::Int\n",
    "    n_epoch_patience::Int\n",
    "    f_average_weights::Bool\n",
    "    f_shuffle_data::Bool\n",
    "    element_type::DataType\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "Models (which are mutable) should not be given internal constructors.\n",
    "**\n",
    "\n",
    "**\n",
    "It is recommended that they be given an external lazy keyword constructor of the same name. This constructor defines default values for every field, and optionally corrects invalid field values by calling a clean! method (whose fallback returns an empty message string):\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keyword constructor\n",
    "function MulticlassPerceptronClassifier( ; \n",
    "                                        n_epochs=100,\n",
    "                                        n_epoch_patience=5,\n",
    "                                        f_average_weights=true,\n",
    "                                        f_shuffle_data=false,\n",
    "                                        element_type=Float32)\n",
    "\n",
    "    model = MulticlassPerceptronClassifier(n_epochs,\n",
    "                                           n_epoch_patience,\n",
    "                                           f_average_weights,\n",
    "                                           f_shuffle_data,\n",
    "                                           element_type)\n",
    "    \n",
    "    message = MLJBase.clean!(model)\n",
    "    isempty(message) || @warn message\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 100,\n",
       "                               n_epoch_patience = 5,\n",
       "                               f_average_weights = true,\n",
       "                               f_shuffle_data = false,\n",
       "                               element_type = Float32,)\u001b[34m @ 3…18\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MulticlassPerceptronClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function MLJBase.clean is used to change the model hyperparameters in case they are set in an invalid way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function MLJ.clean!(model::MulticlassPerceptronClassifier)\n",
    "    warning = \"\"\n",
    "    if model.n_epochs < 1\n",
    "        warning *= \"Need n_epochs ≥ 1. Resetting n_epochs=100 \"\n",
    "        model.n_epochs = 50\n",
    "    end\n",
    "    \n",
    "    if model.n_epoch_patience <1\n",
    "        warning *= \"Need epoch_patience ≥ 1. Resetting epoch_patience=5 \"\n",
    "        model.epoch_patience = 5\n",
    "    end\n",
    "\n",
    "    return warning\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mutable struct MulticlassPerceptronClassifierParameters{T}\n",
    "    W::AbstractMatrix{T}\n",
    "    b::AbstractVector{T}\n",
    "    n_classes::Int\n",
    "    n_features::Int\n",
    "    is_sparse::Bool\n",
    "end\n",
    "\n",
    "#MulticlassPerceptronClassifierParameters(T::Type, n_classes::Int, n_features::Int) = MulticlassPerceptronClassifierParameters{T}(rand(T, n_features, n_classes),\n",
    "#                                                                                       zeros(T, n_classes),\n",
    "#                                                                                       n_classes,\n",
    "#                                                                                       n_features,\n",
    "#                                                                                       is_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifierParameters"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function MulticlassPerceptronClassifierParameters(T::Type, n_classes::Int, n_features::Int, is_sparse::Bool) \n",
    "    \n",
    "    if is_sparse==false\n",
    "        return MulticlassPerceptronClassifierParameters{T}(rand(T, n_features, n_classes),\n",
    "                                                                                       zeros(T, n_classes),\n",
    "                                                                                       n_classes,\n",
    "                                                                                       n_features,\n",
    "                                                                                       is_sparse)\n",
    "    else\n",
    "        return  MulticlassPerceptronClassifierParameters{T}(sparse(rand(T, n_features, n_classes)),\n",
    "                                                            spzeros(T, n_classes),\n",
    "                                                            n_classes,\n",
    "                                                            n_features,\n",
    "                                                            is_sparse)     \n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function MLJBase.fit(model::MulticlassPerceptronClassifier,\n",
    "                     verbosity::Int,   \n",
    "                     X,\n",
    "                     y)\n",
    "    \n",
    "    #Xmatrix = MLJBase.matrix(X)\n",
    "    n_classes    = length(unique(y))\n",
    "    classes_seen = unique(y)\n",
    "    n_features   = size(train_x,1)  # this assumes data comes in cols\n",
    "    \n",
    "    #decode  = MLJBase.decoder(y[1]) # for predict method\n",
    "    decode =  false\n",
    "\n",
    "    # Defining the fitpredict object\n",
    "    is_sparse = issparse(X)\n",
    "    perceptron = MulticlassPerceptronClassifierParameters(model.element_type, n_classes, n_features, is_sparse);\n",
    "    \n",
    "    ### Fitting code starts\n",
    "    fit!(perceptron, X, y; \n",
    "         verbosity=verbosity, \n",
    "         n_epochs=model.n_epochs,\n",
    "         f_average_weights=model.f_average_weights,\n",
    "         f_shuffle_data=model.f_shuffle_data\n",
    "        );   \n",
    "    \n",
    "    ### Fitting code ends\n",
    "    cache = nothing\n",
    "    fitresult = (perceptron, decode)\n",
    "    report = NamedTuple{}()\n",
    "    \n",
    "    #> return package-specific statistics (eg, feature rankings,\n",
    "    #> internal estimates of generalization error) in `report`, which\n",
    "    #> should be a named tuple with the same type every call (can have\n",
    "    #> empty values)\n",
    "    return fitresult, cache, report\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us implement the real `fit!` \n",
    "\n",
    "\n",
    "Notice that the definition of `MLJBase.fit` simply contains code to end up encapsulating the `fit!` method that will actually change the model `perceptron`. Now we will implement this `fit!` method.\n",
    "\n",
    "An important thing that is managed inside `MLJBase.fit` is the encoding and decoding of target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_with_placeholder"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Predicts the class for a given input in a `MulticlassPerceptronClassifier`.\n",
    "The placeholder is used to avoid allocating memory for each matrix-vector multiplication.\n",
    "\n",
    "- Returns the predicted class.\n",
    "\"\"\"\n",
    "function predict_with_placeholder(h::MulticlassPerceptronClassifierParameters, x::AbstractVector, class_placeholder::AbstractVector)\n",
    "    #@fastmath class_placeholder .= At_mul_B!(class_placeholder, h.W, x) .+ h.b\n",
    "    class_placeholder .= mul!(class_placeholder, transpose(h.W), x)  .+ h.b\n",
    "    return argmax(class_placeholder)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Compute the accuracy between `y` and `y_hat`.\n",
    "\"\"\"\n",
    "function accuracy(y::AbstractVector, y_hat::AbstractVector)\n",
    "    acc = 0.\n",
    "    @fastmath for k = 1:length(y)\n",
    "            @inbounds  acc += y[k] == y_hat[k]\n",
    "    end\n",
    "    return acc/length(y_hat)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit!(::MulticlassPerceptronClassifierParameters{Float32}, ::Array{Float32,2}, ::Array{Int64,1}; verbosity=1, n_epochs=10, f_average_weights=true, f_shuffle_data=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "    average_flag=true:\n",
    "        Maintains a running some of the average weight matrix W and bias vector b.\n",
    "\n",
    "        One possible way to do this would be to update the weights after every example is seen  but this\n",
    "        would be less efficient.\n",
    "\"\"\"\n",
    "function fit!(h::MulticlassPerceptronClassifierParameters, X::AbstractArray, y::AbstractVector;\n",
    "              verbosity=0,\n",
    "              n_epochs=50,\n",
    "              learning_rate=1.,\n",
    "              f_average_weights=false,\n",
    "              compute_accuracy=true,\n",
    "              seed=MersenneTwister(1234),\n",
    "              f_shuffle_data=false)\n",
    "    \n",
    "    n_features, n_samples = size(X)\n",
    "    @assert length(y) == n_samples\n",
    "    scores = []\n",
    "    T = eltype(X)\n",
    "    counter           = 0\n",
    "    learning_rate     = T(learning_rate)\n",
    "    class_placeholder = zeros(T, h.n_classes)\n",
    "    y_preds           = zeros(Int16, n_samples)\n",
    "    \n",
    "    data_indices      = Array(1:n_samples)\n",
    "    max_acc           = zero(T)\n",
    "    \n",
    "    if f_average_weights\n",
    "        W_average =  zeros(T, h.n_features, h.n_classes)\n",
    "        b_average =  zeros(T, h.n_classes)\n",
    "    end\n",
    "\n",
    "    @fastmath for epoch in 1:n_epochs\n",
    "\n",
    "        n_mistakes = 0\n",
    "        if f_shuffle_data\n",
    "            shuffle!(seed, data_indices)\n",
    "        end\n",
    "        \n",
    "        @inbounds for m in data_indices\n",
    "            x     = view(X, :, m);\n",
    "            y_hat = predict_with_placeholder(h, x, class_placeholder)\n",
    "            \n",
    "            if y[m] != y_hat\n",
    "                n_mistakes += 1\n",
    "                ####  wij ← wij − η (yj −tj) · xi\n",
    "                h.W[:, y[m]]  .= h.W[:, y[m]]  .+ learning_rate .* x\n",
    "                h.b[y[m]]      = h.b[y[m]]      + learning_rate\n",
    "                h.W[:, y_hat] .= h.W[:, y_hat] .- learning_rate .* x\n",
    "                h.b[y_hat]     = h.b[y_hat]     - learning_rate \n",
    "                \n",
    "                if f_average_weights == true\n",
    "                    counter_learning_rate = counter * learning_rate\n",
    "                    W_average[:, y[m]]   .= W_average[:, y[m]]  .+ counter_learning_rate .* x\n",
    "                    b_average[y[m]]       = b_average[y[m]]      + counter_learning_rate\n",
    "                    W_average[:, y_hat]  .= W_average[:, y_hat] .- counter_learning_rate .* x\n",
    "                    b_average[y_hat]      = b_average[y_hat]     - counter_learning_rate\n",
    "                end\n",
    "            end\n",
    "            counter +=1\n",
    "        end\n",
    "\n",
    "        acc = (n_samples - n_mistakes)/n_samples\n",
    "        # push!(scores, acc) maybe it would be nice to return an array with monitoring metrics to \n",
    "        # allow users to decide if the model has converged\n",
    "       \n",
    "        if verbosity ==1\n",
    "            print(\"\\r\\u1b[K\")\n",
    "            print(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        elseif verbosity ==2\n",
    "            println(\"Epoch: $(epoch) \\t Accuracy: $(round(acc; digits=3))\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if f_average_weights == true\n",
    "        h.W .= h.W  .- W_average./counter \n",
    "        h.b .= h.b  .- b_average./counter\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/davidbuchacaprats/.julia/compiled/v1.1/MLDatasets/9CUQK.ji for MLDatasets [eb30cadb-4394-5ae3-aed4-317e484a6458]\n",
      "└ @ Base loading.jl:1184\n"
     ]
    }
   ],
   "source": [
    "using MLDatasets\n",
    "\n",
    "train_x, train_y = MLDatasets.MNIST.traindata();\n",
    "test_x, test_y   = MLDatasets.MNIST.testdata();\n",
    "train_x          = Float32.(train_x);\n",
    "test_x           = Float32.(test_x);\n",
    "train_y          = train_y .+ 1;\n",
    "test_y           = test_y .+ 1;\n",
    "train_y          = Int64.(train_y);\n",
    "test_y           = Int64.(test_y);\n",
    "train_x          = reshape(train_x, 784, 60000);\n",
    "test_x           = reshape(test_x,  784, 10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 50,\n",
       "                               n_epoch_patience = 5,\n",
       "                               f_average_weights = true,\n",
       "                               f_shuffle_data = false,\n",
       "                               element_type = Float32,)\u001b[34m @ 3…43\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MulticlassPerceptronClassifier(n_epochs=50; f_average_weights=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 50,\n",
       "                               n_epoch_patience = 5,\n",
       "                               f_average_weights = true,\n",
       "                               f_shuffle_data = false,\n",
       "                               element_type = Float32,)\u001b[34m @ 3…43\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KEpoch: 50 \t Accuracy: 0.897  9.294647 seconds (19.64 M allocations: 4.334 GiB, 6.70% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((MulticlassPerceptronClassifierParameters{Float32}(Float32[0.0472152 0.158576 … 0.150542 0.713287; 0.318897 0.981663 … 0.174865 0.830911; … ; 0.592991 0.235063 … 0.668016 0.00751925; 0.797794 0.214817 … 0.761805 0.0689144], Float32[-57.869, 35.9231, 19.744, -22.1515, 5.78087, 102.33, -31.9422, 52.9259, -90.8992, -13.8421], 10, 784, false), false), nothing, NamedTuple())"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time fitresult, _ , _  = MLJBase.fit(model, 1, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a predict\n",
    "\n",
    "In order to predict in MLJ we need 3 things.\n",
    "\n",
    "- The model (abstract model definition with hyperparameters)\n",
    "- The fitresult of the model (containing the learned parameters of the model)\n",
    "- Data\n",
    "\n",
    "\n",
    "#### Example of predict for an SVMC\n",
    "\n",
    "The following code is for predicting with a sklearn SVMC\n",
    "\n",
    "```\n",
    "function MLJBase.predict(model::SVMC\n",
    "                         , fitresult\n",
    "                         , Xnew)\n",
    "\n",
    "    xnew = MLJBase.matrix(Xnew)\n",
    "    result, decode = fitresult\n",
    "    prediction = ScikitLearn.predict(result, xnew)\n",
    "    return decode(prediction)\n",
    "end\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(h::MulticlassPerceptronClassifierParameters, x::AbstractVector, class_placeholder::AbstractVector)\n",
    "    class_placeholder .= mul!(class_placeholder, transpose(h.W), x)  .+ h.b\n",
    "    return argmax(class_placeholder)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function to predict the class for a given input batch.\n",
    "- Returns the predicted class.\n",
    "\"\"\"\n",
    "function predict(h::MulticlassPerceptronClassifierParameters, X::AbstractMatrix)\n",
    "    predictions = zeros(Int64, size(X, 2))\n",
    "    class_placeholder = zeros(eltype(h.W), h.n_classes)\n",
    "\n",
    "    @inbounds for m in 1:length(predictions)\n",
    "        predictions[m] = predict(h, view(X,:,m), class_placeholder)\n",
    "    end\n",
    "    \n",
    "    return predictions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function MLJBase.predict(model::MulticlassPerceptronClassifier, fitresult, Xnew)\n",
    "    xnew = MLJBase.matrix(Xnew)\n",
    "    result, decode = fitresult\n",
    "    prediction = predict(result, xnew)\n",
    "    #decode(prediction)\n",
    "    return prediction \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.010755 seconds (4.01 k allocations: 3.106 MiB, 59.31% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time MLJBase.predict(model,fitresult, train_x[:,1:1000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.002261 seconds (4.01 k allocations: 117.750 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time MLJBase.predict(model,fitresult, view(train_x,:,1:1000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9357166666666666, test accuracy: 0.9264\n"
     ]
    }
   ],
   "source": [
    "y_tr_preds = MLJBase.predict(model,fitresult,train_x);\n",
    "y_te_preds = MLJBase.predict(model,fitresult,test_x);\n",
    "\n",
    "acc_tr = mean(y_tr_preds .== train_y)\n",
    "acc_te = mean(y_te_preds .== test_y)\n",
    "\n",
    "println(\"train accuracy: $acc_tr, test accuracy: $acc_te\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Allowing fit(model,X,y) with categorical arrays\n",
    "\n",
    "\n",
    "Assume that the data is given with a categorical label which can be represented on when loaded as a string.\n",
    "\n",
    "Since our target values are actually integers we will create the scenario we want to test with the `catname` mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this cell retwrites targets as strings to show the point \n",
    "# of using CategoricalArrays\n",
    "\n",
    "catname = Dict(1 => \"one\",\n",
    "               2 => \"two\",\n",
    "               3 => \"three\",\n",
    "               4 => \"four\",\n",
    "               5 => \"five\",\n",
    "               6 => \"six\",\n",
    "               7 => \"seven\",\n",
    "               8 => \"eight\",\n",
    "               9 => \"nine\",\n",
    "               10 => \"ten\");\n",
    "\n",
    "train_y_labels = [catname[i] for i in train_y];\n",
    "test_y_labels  = [catname[i] for i in test_y];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us imagine that we are given the data in the following format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{String,1}:\n",
       " \"six\" \n",
       " \"one\" \n",
       " \"five\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_labels[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we should take care of rewritting classes as numbers from 1 to N before we fit our model\n",
    "(our MulticlassPerceptron implementation uses the indices of the classes update the weight vectors assigned to those indices).\n",
    "\n",
    "We can make our MLJ model do this automatically inside the `fit` method as long as we provide `train_y_labels`  as a CategoricalArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y_cat = CategoricalArray(train_y_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CategoricalArray{String,1,UInt32}:\n",
       " \"six\"  \n",
       " \"one\"  \n",
       " \"five\" \n",
       " \"two\"  \n",
       " \"ten\"  \n",
       " \"three\"\n",
       " \"two\"  \n",
       " \"four\" \n",
       " \"two\"  \n",
       " \"five\" "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_cat[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A categorical array will contain\n",
    "\n",
    "- `x.pool` all possible categories found.\n",
    "- `x.refs` each value of the array encoded as a refenrence to an element in the pool.\n",
    "- `levels(x)` returns the possible levels (categories) of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(train_y_cat.pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalArray{String,1,UInt32}:\n",
       " \"six\" \n",
       " \"one\" \n",
       " \"five\"\n",
       " \"two\" \n",
       " \"ten\" "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_cat[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalPool{String,UInt32}([\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"ten\",\"three\",\"two\"])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_cat.pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{UInt32,1}:\n",
       " 0x00000001\n",
       " 0x00000002\n",
       " 0x00000003\n",
       " 0x00000004\n",
       " 0x00000005"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_cat.refs[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{String,1}:\n",
       " \"eight\"\n",
       " \"five\" \n",
       " \"four\" \n",
       " \"nine\" \n",
       " \"one\"  \n",
       " \"seven\"\n",
       " \"six\"  \n",
       " \"ten\"  \n",
       " \"three\"\n",
       " \"two\"  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels(train_y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{UInt32,1}:\n",
       " 0x00000007\n",
       " 0x00000005\n",
       " 0x00000002\n",
       " 0x0000000a\n",
       " 0x00000008\n",
       " 0x00000009\n",
       " 0x0000000a\n",
       " 0x00000003\n",
       " 0x0000000a\n",
       " 0x00000002"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(train_y_cat[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CategoricalArray{String,1,UInt32}:\n",
       " \"six\"  \n",
       " \"one\"  \n",
       " \"five\" \n",
       " \"two\"  \n",
       " \"ten\"  \n",
       " \"three\"\n",
       " \"two\"  \n",
       " \"four\" \n",
       " \"two\"  \n",
       " \"five\" "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_cat[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping categories with a `MLJBase.decoder`\n",
    "\n",
    "If we want to map from numbers back to strings we need a `MLJBase.CategoricalDecoder` dictionary which can be created using `decoder` from MLJBase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJBase.CategoricalDecoder{String,UInt32}(CategoricalPool{String,UInt32}([\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"ten\",\"three\",\"two\"]), [9, 3, 7, 10, 2, 8, 1, 5, 6, 4])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLJBase\n",
    "dec = decoder(train_y_cat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalArray{String,1,UInt32}:\n",
       " \"six\" \n",
       " \"one\" \n",
       " \"five\"\n",
       " \"two\" \n",
       " \"ten\" "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(MLJ.int(train_y_cat[1:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element CategoricalArray{String,1,UInt32}:\n",
       " \"eight\"\n",
       " \"eight\"\n",
       " \"five\" "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec([1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalPool{String,UInt32}([\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"ten\",\"three\",\"two\"])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CategoricalString{UInt32} \"seven\", 6)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(train_y[1]), train_y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving `MLJBase.fit` \n",
    "\n",
    "Now we have all ingredients to create\n",
    "\n",
    "`MLJBase.fit(model::MulticlassPerceptronClassifier, verbosity,X,y)`\n",
    "\n",
    "Which accepts as input `y` as a Categorical array. Then it does the following:\n",
    "\n",
    "- Takes a single element from the categorical array (which stores all possible class labels) and from this element it creates  a decoding function that, given an integer it returns back a category. \n",
    "\n",
    "```julia\n",
    "    # decoder maps Integer->Category, used in the predict method\n",
    "    decode  = MLJBase.decoder(y[1]) \n",
    "```\n",
    "\n",
    "\n",
    "- It maps the categorical array to integers:\n",
    "```julia\n",
    "   # Encodes CategoricalArray to an Array of integers\n",
    "   y = Int.(int(y))  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "function MLJBase.fit(model::MulticlassPerceptronClassifier,\n",
    "                     verbosity::Int,   \n",
    "                     X,\n",
    "                     y)\n",
    "    \n",
    "    #Xmatrix = MLJBase.matrix(X)\n",
    "    n_classes    = length(unique(y))\n",
    "    classes_seen = unique(y)\n",
    "    n_features   = size(X,1)  # this assumes data comes in cols\n",
    "\n",
    "    decode  = MLJBase.decoder(y[1]) # for the predict method\n",
    "    y = Int.(int(y))                # Encoding categorical target as array of integers\n",
    "\n",
    "    is_sparse = issparse(X)\n",
    "    perceptron = MulticlassPerceptronClassifierParameters(model.element_type, n_classes,\n",
    "                                                          n_features, is_sparse);\n",
    "\n",
    "    ### Fitting code starts\n",
    "    fit!(perceptron, X, y; \n",
    "         verbosity=verbosity, \n",
    "         n_epochs=model.n_epochs,\n",
    "         f_average_weights=model.f_average_weights,\n",
    "         f_shuffle_data=model.f_shuffle_data\n",
    "        ); \n",
    "    \n",
    "    ### Fitting code ends\n",
    "    cache = nothing\n",
    "    fitresult = (perceptron, decode)\n",
    "    report = NamedTuple{}()\n",
    "    \n",
    "    #> return package-specific statistics (eg, feature rankings,\n",
    "    #> internal estimates of generalization error) in `report`, which\n",
    "    #> should be a named tuple with the same type every call (can have\n",
    "    #> empty values)\n",
    "    return fitresult, cache, report\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassPerceptronClassifier(n_epochs = 20,\n",
       "                               n_epoch_patience = 5,\n",
       "                               f_average_weights = true,\n",
       "                               f_shuffle_data = false,\n",
       "                               element_type = Float32,)\u001b[34m @ 5…63\u001b[39m"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MulticlassPerceptronClassifier(n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KEpoch: 20 \t Accuracy: 0.895  3.943002 seconds (8.03 M allocations: 1.803 GiB, 8.18% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((MulticlassPerceptronClassifierParameters{Float32}(Float32[0.710199 0.0529157 … 0.510163 0.294064; 0.202259 0.335671 … 0.2358 0.649653; … ; 0.767949 0.368562 … 0.443363 0.195588; 0.0152253 0.347191 … 0.132136 0.191593], Float32[48.2356, 4.86863, -17.8378, -85.813, -51.9692, -26.1452, 97.9318, -15.823, 18.6719, 27.8803], 10, 784, false), MLJBase.CategoricalDecoder{String,UInt32}(CategoricalPool{String,UInt32}([\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"ten\",\"three\",\"two\"]), [9, 3, 7, 10, 2, 8, 1, 5, 6, 4])), nothing, NamedTuple())"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time fitresult, _ , _  = MLJBase.fit(model, 1, train_x, train_y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJBase.CategoricalDecoder{String,UInt32}(CategoricalPool{String,UInt32}([\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"ten\",\"three\",\"two\"]), [9, 3, 7, 10, 2, 8, 1, 5, 6, 4])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = fitresult[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalString{UInt32} \"five\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function MLJBase.predict(model::MulticlassPerceptronClassifier, fitresult, Xnew)\n",
    "    xnew = MLJBase.matrix(Xnew)\n",
    "    result, decode = fitresult\n",
    "    prediction = predict(result, xnew)\n",
    "    return decode(prediction)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element CategoricalArray{String,1,UInt32}:\n",
       " \"six\" \n",
       " \"one\" \n",
       " \"five\"\n",
       " \"two\" "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLJBase.predict(model, fitresult, train_x[:,1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use directly `.predict`  and get an array with categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.93405, test accuracy: 0.9268\n"
     ]
    }
   ],
   "source": [
    "train_y_labels = [catname[i] for i in train_y];\n",
    "test_y_labels  = [catname[i] for i in test_y];\n",
    "\n",
    "y_tr_cat   = CategoricalArray(train_y_labels);\n",
    "y_te_cat   = CategoricalArray(test_y_labels);\n",
    "\n",
    "y_tr_preds = MLJBase.predict(model,fitresult,train_x);\n",
    "y_te_preds = MLJBase.predict(model,fitresult,test_x);\n",
    "\n",
    "acc_tr = mean(y_tr_preds .== y_tr_cat)\n",
    "acc_te = mean(y_te_preds .== y_te_cat)\n",
    "\n",
    "println(\"train accuracy: $acc_tr, test accuracy: $acc_te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction types for deterministic responses.\n",
    "\n",
    "In the case of Deterministic models, yhat should be an AbstractVector (commonly a plain Vector) with the same element type as the target y passed to the fit method (see above). Any CategoricalValue or CategoricalString appearing in yhat must have the same levels in its pool as was present in the elements of the target y presented in training, even if not all levels appear in the training data or prediction itself. For example, in the univariate target case, this means MLJ.classes(yhat[i]) = MLJ.classes(y[j]) for all admissible i and j. (The method classes is described under Convenience methods below).\n",
    "\n",
    "Unfortunately, code not written with the preservation of categorical levels in mind poses special problems. To help with this, MLJBase provides three utility methods: int (for converting a CategoricalValue or CategoricalString into an integer, the ordering of these integers being consistent with that of the pool), decoder (for constructing a callable object that decodes the integers back into CategoricalValue/CategoricalString objects), and classes, for extracting the complete pool from a single value. Refer to Convenience methods below for important details.\n",
    "\n",
    "Note that a decoder created during fit may need to be bundled with fitresult to make it available to predict during re-encoding. So, for example, if the core algorithm being wrapped by fit expects a nominal target yint of type Vector{<:Integer} then a fit method may look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant material about Perceptrons\n",
    "\n",
    "\n",
    "https://www.codingame.com/playgrounds/9487/deep-learning-from-scratch---theory-and-implementation/perceptrons\n",
    "\n",
    "\n",
    "https://datascienceplus.com/mnist-for-machine-learning-beginners-with-softmax-regression/\n",
    "\n",
    "\n",
    "https://medium.com/tebs-lab/how-to-classify-mnist-digits-with-different-neural-network-architectures-39c75a0f03e3\n",
    "\n",
    "\n",
    "\n",
    "https://www.cs.utah.edu/~zhe/pdf/\n",
    "\n",
    "\n",
    "#### Adding to the package\n",
    "\n",
    "\n",
    "- Improve performance, how can we select columns from the traning data without generating views?\n",
    "\n",
    "\n",
    "- Add Mira implementation of a multiclas perceptron.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
